#!/usr/bin/env python3
"""RNDèŠ‚ç‚¹ç¨‹åºï¼šå¤šèŠ‚ç‚¹é›†ç¾¤ï¼ˆ9755/9756ç«¯å£) - æ— ç®—åŠ›+åŠ¨æ€ç™½åå•+é˜²ç¯¡æ”¹ç‰ˆ"""
import json
import time
import hashlib
import http.server
import socketserver
import sqlite3
import threading
import requests
from dataclasses import dataclass, asdict
from nacl.signing import SigningKey, VerifyKey
import nacl.encoding
from typing import List, Dict, Set, Optional, Tuple
import random
from cryptography.fernet import Fernet
import os
import socket
import atexit

# ---------- èŠ‚ç‚¹æ ¸å¿ƒé…ç½® ----------
PORT = 9756  # ä¸»æœåŠ¡ç«¯å£
DB_FILE = "node.db"  # å…¨é‡å­˜å‚¨æ•°æ®åº“
REWARD = 1280
TOTAL_SUPPLY_LIMIT = 12800000000
FEE = 1
TIMEOUT = 180
SYNC_INTERVAL = 10
P2P_DISCOVERY_PORT = 9755 # P2Pç«¯å£
TX_SYNC_INTERVAL = 10
WALLET_DIR = "./rnd_wallet"  # ç‹¬ç«‹é’±åŒ…ç›®å½•
ENCRYPT_KEY_FILE = f"{WALLET_DIR}/encrypt_key.key"
CURRENT_NODE_PUBLIC_IP = "62.234.183.74"  # èŠ‚ç‚¹å…¬ç½‘IPï¼ˆå¯ä¿®æ”¹ä¸ºå®é™…IPï¼‰
P2P_SEEDS = ["82.157.37.13:9753"]  # å¯¹ç­‰èŠ‚ç‚¹ï¼Œå¯å¡«å†™å¤šä¸ª
MAX_TX_POOL_SIZE = 1000  # äº¤æ˜“æ± æœ€å¤§å®¹é‡
REQUEST_LIMIT_PER_MINUTE = 100  # å•IPæ¯åˆ†é’Ÿæœ€å¤§è¯·æ±‚æ•°

# 36ä½åœ°å€é…ç½®ï¼ˆRNDCå‰ç¼€+32ä½å“ˆå¸Œï¼‰
ADDRESS_PREFIX = "RNDC"
ADDRESS_LENGTH = 36  # å‰ç¼€4ä½ + å“ˆå¸Œ32ä½
VALID_CHARS = "23456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz"  # è¿‡æ»¤æ¨¡ç³Šå­—ç¬¦

# ç™½åå•é…ç½®ï¼ˆæ ¸å¿ƒæ–°å¢ï¼‰
WHITELIST_CONSENSUS_RATIO = 0.6  # æ–°å¢èŠ‚ç‚¹éœ€60%ä»¥ä¸Šå·²è®¤è¯èŠ‚ç‚¹è®¤å¯
WHITELIST_VALIDITY_PERIOD = 86400  # ç™½åå•æœ‰æ•ˆæœŸ24å°æ—¶
IP_BIND_LOCK = threading.Lock()

# ---------- å…¨å±€å˜é‡ ----------
NODE_ADDR = ""
NODE_KEY = None
ENCRYPTOR = None
NODE_IP = ""
P2P_PEERS = {}
GLOBAL_QUEUE = []
TX_POOL = []
BALANCE_CACHE = {}  # {addr_maxheight: balance}
IP_ADDR_MAP = {}
ADDR_IP_MAP = {}
IP_REQUEST_COUNT = {}  # {ip: (count, last_reset_time)} é™æµç”¨
QUEUE_LOCK = threading.Lock()
TX_POOL_LOCK = threading.Lock()
IS_SYNCING = False
IS_TX_SYNCING = False
IS_FULLY_SYNCED = False
P2P_HEIGHT_CACHE = {}  # {peer_main_addr: (height, timestamp)}
GLOBAL_REQUEST_SEMAPHORE = threading.Semaphore(20)  # å…¨å±€å¹¶å‘é™åˆ¶

# ç™½åå•ç›¸å…³å…¨å±€å˜é‡ï¼ˆæ ¸å¿ƒæ–°å¢ï¼‰
AUTHENTICATED_NODES = set()  # å·²è®¤è¯çš„åˆæ³•èŠ‚ç‚¹ï¼ˆç™½åå•ï¼‰
NODE_WHITELIST_REQUESTS = {}  # ç™½åå•åŠ å…¥è¯·æ±‚ï¼š{èŠ‚ç‚¹åœ°å€: {è®¤å¯èŠ‚ç‚¹: æ—¶é—´}}

# ---------- æ ¸å¿ƒæ•°æ®ç»“æ„ ----------
@dataclass
class Block:
    height: int
    prev_hash: str
    miner: str
    txs: List[Dict]
    reward: int

# ---------- å·¥å…·å‡½æ•° ----------
def log_print(msg: str):
    """å¸¦æ—¶é—´æˆ³çš„æ—¥å¿—æ‰“å°å‡½æ•°"""
    timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
    print(f"[{timestamp}] {msg}")

def get_local_ip() -> str:
    """è·å–æœ¬åœ°IP"""
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        s.connect(('8.8.8.8', 80))
        ip = s.getsockname()[0]
    finally:
        s.close()
    return ip

def init_wallet_dir():
    """åˆå§‹åŒ–é’±åŒ…å­˜å‚¨ç›®å½•"""
    os.makedirs(WALLET_DIR, exist_ok=True)
    # ç”ŸæˆåŠ å¯†å¯†é’¥ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
    if not os.path.exists(ENCRYPT_KEY_FILE):
        encrypt_key = Fernet.generate_key()
        with open(ENCRYPT_KEY_FILE, "wb") as f:
            f.write(encrypt_key)
    # åŠ è½½åŠ å¯†å™¨
    with open(ENCRYPT_KEY_FILE, "rb") as f:
        encrypt_key = f.read()
    return Fernet(encrypt_key)

def generate_36bit_address(public_key: str) -> str:
    """ç”Ÿæˆ36ä½RNDCåœ°å€ï¼ˆè¿‡æ»¤æ¨¡ç³Šå­—ç¬¦ï¼‰"""
    hash_hex = hashlib.sha256(public_key.encode()).hexdigest()[:64]
    filtered_chars = [c for c in hash_hex if c in VALID_CHARS][:32]
    address = f"{ADDRESS_PREFIX}{''.join(filtered_chars)}"
    if len(address) != ADDRESS_LENGTH:
        raise ValueError(f"åœ°å€ç”Ÿæˆå¤±è´¥ï¼šé•¿åº¦ä¸º{len(address)}ä½ï¼ˆé¢„æœŸ36ä½ï¼‰")
    return address

def load_wallet(encryptor: Fernet) -> Optional[Tuple[SigningKey, str, str]]:
    """åŠ è½½å·²å­˜åœ¨çš„é’±åŒ…"""
    wallet_files = [f for f in os.listdir(WALLET_DIR) if f.startswith("rndc_wallet_") and f.endswith(".json")]
    if not wallet_files:
        return None
    wallet_path = os.path.join(WALLET_DIR, wallet_files[0])
    with open(wallet_path, "rb") as f:
        encrypted_data = f.read()
    data = json.loads(encryptor.decrypt(encrypted_data).decode())
    private_key = SigningKey(data["private_key"], encoder=nacl.encoding.HexEncoder)
    public_key = data["public_key"]
    address = data["address"]
    return private_key, public_key, address

def create_new_wallet(encryptor: Fernet) -> Tuple[SigningKey, str, str]:
    """åˆ›å»ºæ–°é’±åŒ…ï¼ˆ36ä½RNDCåœ°å€ï¼‰"""
    private_key = SigningKey.generate()
    public_key = private_key.verify_key.encode(encoder=nacl.encoding.HexEncoder).decode()
    address = generate_36bit_address(public_key)
    # åŠ å¯†å­˜å‚¨
    wallet_data = {
        "private_key": private_key.encode(encoder=nacl.encoding.HexEncoder).decode(),
        "public_key": public_key,
        "address": address,
        "create_time": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
    }
    wallet_path = os.path.join(WALLET_DIR, f"rndc_wallet_{address}.json")
    with open(wallet_path, "wb") as f:
        f.write(encryptor.encrypt(json.dumps(wallet_data).encode()))
    print(f"âœ… æ–°é’±åŒ…åˆ›å»ºæˆåŠŸï¼")
    print(f"  address: {address}")
    print(f"ğŸ”‘ ç§é’¥å·²åŠ å¯†å­˜å‚¨ï¼ˆè·¯å¾„ï¼š{wallet_path}ï¼‰")
    return private_key, public_key, address

def init_wallet() -> Tuple[SigningKey, str, Fernet]:
    """èŠ‚ç‚¹é’±åŒ…åˆå§‹åŒ–å…¥å£ï¼ˆåŠ è½½å·²æœ‰/åˆ›å»ºæ–°é’±åŒ…ï¼‰"""
    encryptor = init_wallet_dir()
    wallet = load_wallet(encryptor)
    if wallet:
        private_key, public_key, address = wallet
        log_print(f"[é’±åŒ…åŠ è½½] 36ä½åœ°å€ï¼š{address}")
        return private_key, address, encryptor
    # æ²¡æœ‰åˆ™åˆ›å»ºæ–°é’±åŒ…
    private_key, public_key, address = create_new_wallet(encryptor)
    log_print(f"[é’±åŒ…ç”Ÿæˆ] 36ä½åœ°å€ï¼š{address}")
    return private_key, address, encryptor

def bind_ip_address(ip: str, addr: str):
    """ç»‘å®šIPä¸åœ°å€"""
    with IP_BIND_LOCK:
        IP_ADDR_MAP[ip] = addr
        ADDR_IP_MAP[addr] = ip
        conn = sqlite3.connect(DB_FILE)
        cur = conn.cursor()
        cur.execute("CREATE TABLE IF NOT EXISTS ip_addr_map(ip TEXT PRIMARY KEY, addr TEXT)")
        cur.execute("INSERT OR REPLACE INTO ip_addr_map(ip, addr) VALUES (?, ?)", (ip, addr))
        conn.commit()
        conn.close()

def load_ip_addr_map():
    """åŠ è½½IPä¸åœ°å€æ˜ å°„"""
    try:
        conn = sqlite3.connect(DB_FILE)
        cur = conn.cursor()
        cur.execute("CREATE TABLE IF NOT EXISTS ip_addr_map(ip TEXT PRIMARY KEY, addr TEXT)")
        rows = cur.execute("SELECT ip, addr FROM ip_addr_map").fetchall()
        conn.close()
        with IP_BIND_LOCK:
            for ip, addr in rows:
                IP_ADDR_MAP[ip] = addr
                ADDR_IP_MAP[addr] = ip
    except Exception as e:
        log_print(f"[é”™è¯¯] IPæ˜ å°„åŠ è½½å¤±è´¥ï¼š{e}")

def load_p2p_peers():
    """åŠ è½½P2PèŠ‚ç‚¹åˆ—è¡¨"""
    try:
        conn = sqlite3.connect(DB_FILE)
        cur = conn.cursor()
        cur.execute("CREATE TABLE IF NOT EXISTS p2p_peers(peer_addr TEXT PRIMARY KEY, add_time REAL)")
        rows = cur.execute("SELECT peer_addr, add_time FROM p2p_peers").fetchall()
        conn.close()
        with IP_BIND_LOCK:
            for addr, add_time in rows:
                P2P_PEERS[addr] = add_time
    except Exception as e:
        log_print(f"[é”™è¯¯] P2PèŠ‚ç‚¹åŠ è½½å¤±è´¥ï¼š{e}")

# ---------- å®‰å…¨ç›¸å…³å‡½æ•° ----------
def is_valid_address(addr: str) -> bool:
    """éªŒè¯åœ°å€æ˜¯å¦ä¸º36ä½RNDCæ ¼å¼"""
    return len(addr) == ADDRESS_LENGTH and addr.startswith(ADDRESS_PREFIX)

def verify_tx_signature(tx: Dict) -> bool:
    """éªŒè¯äº¤æ˜“ç­¾åæœ‰æ•ˆæ€§"""
    required_fields = ["sender", "signature", "public_key", "amount", "recipient", "nonce"]
    if not all(field in tx for field in required_fields):
        log_print(f"[äº¤æ˜“éªŒè¯å¤±è´¥] å­—æ®µç¼ºå¤±")
        return False
    # éªŒè¯åœ°å€æ ¼å¼
    if not is_valid_address(tx["sender"]) or not is_valid_address(tx["recipient"]):
        log_print(f"[äº¤æ˜“éªŒè¯å¤±è´¥] åœ°å€æ ¼å¼æ— æ•ˆ")
        return False
    try:
        public_key = VerifyKey(tx["public_key"], encoder=nacl.encoding.HexEncoder)
        tx_data = {k: v for k, v in tx.items() if k != "signature"}
        tx_json = json.dumps(tx_data, sort_keys=True).encode()
        public_key.verify(tx_json, bytes.fromhex(tx["signature"]))
        return True
    except Exception as e:
        log_print(f"[äº¤æ˜“éªŒè¯å¤±è´¥] {tx['sender'][:8]}ï¼š{e}")
        return False

def is_peer_alive(peer_main_addr: str) -> bool:
    """æ£€æµ‹P2PèŠ‚ç‚¹æ˜¯å¦å­˜æ´»"""
    try:
        resp = requests.get(f"http://{peer_main_addr}/json/chain_height", timeout=5)
        return resp.status_code == 200
    except Exception:
        return False

# ---------- åŒºå—ç›¸å…³å‡½æ•° ----------
def init_full_chain_db():
    """åˆå§‹åŒ–å…¨é‡åŒºå—æ•°æ®åº“ï¼ˆå«å“ˆå¸Œå­—æ®µï¼‰"""
    conn = sqlite3.connect(DB_FILE)
    cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS blocks (
            height INTEGER PRIMARY KEY,
            prev_hash TEXT NOT NULL,
            miner TEXT NOT NULL,
            txs TEXT NOT NULL,
            reward INTEGER NOT NULL,
            create_time REAL NOT NULL,
            block_hash TEXT NOT NULL UNIQUE  -- å­˜å‚¨åŒºå—å“ˆå¸Œï¼Œç”¨äºé˜²ç¯¡æ”¹
        )
    """)
    conn.commit()
    conn.close()

def get_total_supply(up_to_height: int = None) -> int:
    """è·å–æŒ‡å®šé«˜åº¦å‰çš„æ€»å‘è¡Œé‡"""
    if up_to_height is None:
        up_to_height = get_chain_height()
    try:
        conn = sqlite3.connect(DB_FILE)
        cur = conn.cursor()
        cur.execute("SELECT SUM(reward) FROM blocks WHERE height <= ?", (up_to_height,))
        row = cur.fetchone()
        conn.close()
        return row[0] if row[0] is not None else 0
    except Exception as e:
        log_print(f"[é”™è¯¯] è®¡ç®—æ€»å‘è¡Œé‡å¤±è´¥ï¼š{e}")
        return 0

def verify_block_chain(height: int) -> bool:
    """éªŒè¯åŒºå—é“¾å®Œæ•´æ€§"""
    if height == 0:
        return True
    current_block = get_block_from_full_chain(height)
    prev_block = get_block_from_full_chain(height - 1)
    if not current_block or not prev_block:
        return False
    # éªŒè¯çŸ¿å·¥åœ°å€æ ¼å¼
    if not is_valid_address(current_block.miner):
        log_print(f"[åŒºå—éªŒè¯å¤±è´¥] é«˜åº¦{height}çŸ¿å·¥åœ°å€æ ¼å¼æ— æ•ˆ")
        return False
    prev_block_hash = hashlib.sha256(json.dumps(asdict(prev_block)).encode()).hexdigest()
    return current_block.prev_hash == prev_block_hash

def get_block_from_full_chain(height: int) -> Optional[Block]:
    """ä»å…¨é‡æ•°æ®åº“æŸ¥è¯¢åŒºå—"""
    try:
        conn = sqlite3.connect(DB_FILE)
        cur = conn.cursor()
        cur.execute("SELECT prev_hash, miner, txs, reward FROM blocks WHERE height=?", (height,))
        row = cur.fetchone()
        conn.close()
        if row:
            return Block(
                height=height,
                prev_hash=row[0],
                miner=row[1],
                txs=json.loads(row[2]),
                reward=row[3]
            )
    except Exception as e:
        log_print(f"[é”™è¯¯] æŸ¥è¯¢åŒºå—{height}å¼‚å¸¸ï¼š{e}")
    return None

def save_block_to_full_chain(block: Block):
    """ä¿å­˜åŒºå—ï¼ˆå¼ºåŒ–æ ¡éªŒï¼šç™½åå•+å¥–åŠ±+äº¤æ˜“åˆæ³•æ€§ï¼‰"""
    # 1. æ ¡éªŒçŸ¿å·¥æ˜¯å¦åœ¨ç™½åå•
    if block.miner not in AUTHENTICATED_NODES:
        log_print(f"[ä¿å­˜å¤±è´¥] åŒºå—{block.height}çŸ¿å·¥{block.miner[:8]}... ä¸åœ¨ç™½åå•")
        return
    # 2. æ ¡éªŒå¥–åŠ±åˆæ³•æ€§
    current_supply = get_total_supply()
    valid_reward = REWARD if (current_supply + REWARD) <= TOTAL_SUPPLY_LIMIT else 0
    if block.reward != valid_reward:
        log_print(f"[ä¿å­˜å¤±è´¥] åŒºå—{block.height}å¥–åŠ±å¼‚å¸¸ï¼ˆé¢„æœŸ{valid_reward}ï¼Œå®é™…{block.reward}ï¼‰")
        return
    # 3. æ ¡éªŒåŒºå—é«˜åº¦è¿ç»­æ€§
    current_max_height = get_chain_height()
    if block.height != current_max_height + 1:
        log_print(f"[ä¿å­˜å¤±è´¥] åŒºå—{block.height}é«˜åº¦ä¸è¿ç»­ï¼ˆå½“å‰æœ€é«˜{current_max_height}ï¼‰")
        return
    # 4. æ ¡éªŒçŸ¿å·¥åœ°å€æ ¼å¼
    if not is_valid_address(block.miner):
        log_print(f"[ä¿å­˜å¤±è´¥] åŒºå—{block.height}çŸ¿å·¥åœ°å€æ ¼å¼æ— æ•ˆ")
        return
    # 5. æ ¡éªŒäº¤æ˜“åˆæ³•æ€§
    for tx in block.txs:
        if not verify_tx_signature(tx):
            log_print(f"[ä¿å­˜å¤±è´¥] åŒºå—{block.height}åŒ…å«æ— æ•ˆäº¤æ˜“ï¼š{tx['sender'][:8]}...")
            return
        sender_bal = get_balance_from_cache(tx["sender"], current_max_height)
        if sender_bal < (tx["amount"] + FEE):
            log_print(f"[ä¿å­˜å¤±è´¥] åŒºå—{block.height}äº¤æ˜“ä½™é¢ä¸è¶³")
            return
    # 6. è®¡ç®—å¹¶å­˜å‚¨åŒºå—å“ˆå¸Œï¼ˆé˜²ç¯¡æ”¹ï¼‰
    block_dict = asdict(block)
    block_hash = hashlib.sha256(json.dumps(block_dict, sort_keys=True).encode()).hexdigest()
    # 7. ä¿å­˜åˆ°æ•°æ®åº“
    conn = sqlite3.connect(DB_FILE)
    cur = conn.cursor()
    cur.execute("""
        INSERT OR REPLACE INTO blocks 
        (height, prev_hash, miner, txs, reward, create_time, block_hash)
        VALUES (?, ?, ?, ?, ?, ?, ?)
    """, (
        block.height,
        block.prev_hash,
        block.miner,
        json.dumps(block.txs),
        block.reward,
        time.time(),
        block_hash
    ))
    conn.commit()
    conn.close()
    log_print(f"[å…¨é‡å­˜å‚¨] åŒºå—{block.height}å·²ä¿å­˜ï¼ˆçŸ¿å·¥ï¼š{block.miner[:8]}... å“ˆå¸Œï¼š{block_hash[:8]}...ï¼‰")
    # 8. æ¸…ç†ç›¸å…³åœ°å€ä½™é¢ç¼“å­˜
    with IP_BIND_LOCK:
        cache_keys = list(BALANCE_CACHE.keys())
        related_addrs = {block.miner}
        for tx in block.txs:
            related_addrs.add(tx["sender"])
            related_addrs.add(tx["recipient"])
        for key in cache_keys:
            addr = key.split("_")[0]
            if addr in related_addrs:
                del BALANCE_CACHE[key]

def get_chain_height() -> int:
    """è·å–å…¨é‡é“¾çš„æœ€é«˜é«˜åº¦"""
    try:
        conn = sqlite3.connect(DB_FILE)
        cur = conn.cursor()
        cur.execute("SELECT MAX(height) FROM blocks")
        row = cur.fetchone()
        conn.close()
        return row[0] if row[0] is not None else 0
    except Exception as e:
        log_print(f"[é”™è¯¯] æŸ¥è¯¢é“¾é«˜å¼‚å¸¸ï¼š{e}")
        return 0

def verify_local_chain_integrity():
    """å¯åŠ¨æ—¶æ ¡éªŒæœ¬åœ°æ•°æ®å®Œæ•´æ€§ï¼ˆé˜²ç¯¡æ”¹ï¼‰"""
    log_print("[æ ¡éªŒ] å¼€å§‹æœ¬åœ°é“¾å®Œæ•´æ€§æ ¡éªŒ...")
    max_height = get_chain_height()
    invalid_blocks = []
    for height in range(1, max_height + 1):
        try:
            conn = sqlite3.connect(DB_FILE)
            cur = conn.cursor()
            cur.execute("SELECT prev_hash, miner, txs, reward, block_hash FROM blocks WHERE height=?", (height,))
            row = cur.fetchone()
            conn.close()
            if not row:
                invalid_blocks.append(f"é«˜åº¦{height}ï¼šåŒºå—ç¼ºå¤±")
                continue
            prev_hash, miner, txs, reward, stored_hash = row
            # æ ¡éªŒå¥–åŠ±åˆæ³•æ€§
            current_supply = get_total_supply(height - 1)
            valid_reward = REWARD if (current_supply + REWARD) <= TOTAL_SUPPLY_LIMIT else 0
            if reward != valid_reward:
                invalid_blocks.append(f"é«˜åº¦{height}ï¼šå¥–åŠ±å¼‚å¸¸ï¼ˆå®é™…{reward}ï¼Œé¢„æœŸ{valid_reward}ï¼‰")
            # æ ¡éªŒåŒºå—å“ˆå¸Œ
            block = Block(
                height=height,
                prev_hash=prev_hash,
                miner=miner,
                txs=json.loads(txs),
                reward=reward
            )
            calc_hash = hashlib.sha256(json.dumps(asdict(block), sort_keys=True).encode()).hexdigest()
            if calc_hash != stored_hash:
                invalid_blocks.append(f"é«˜åº¦{height}ï¼šå“ˆå¸Œç¯¡æ”¹ï¼ˆå­˜å‚¨{stored_hash[:8]}... è®¡ç®—{calc_hash[:8]}...ï¼‰")
        except Exception as e:
            invalid_blocks.append(f"é«˜åº¦{height}ï¼šæ ¡éªŒå¤±è´¥ï¼š{str(e)}")
    # è¾“å‡ºç»“æœ
    if invalid_blocks:
        log_print(f"[é”™è¯¯] å‘ç°{len(invalid_blocks)}ä¸ªç¯¡æ”¹/å¼‚å¸¸åŒºå—ï¼Œå»ºè®®é‡ç½®æ•°æ®ï¼")
        for err in invalid_blocks[:5]:
            log_print(f"  - {err}")
    else:
        log_print(f"[æ ¡éªŒå®Œæˆ] æœ¬åœ°é“¾ï¼ˆé«˜åº¦{max_height}ï¼‰æ— ç¯¡æ”¹ï¼Œæ•°æ®å®Œæ•´")

# ---------- ç™½åå•ç®¡ç†å‡½æ•°ï¼ˆæ ¸å¿ƒæ–°å¢ï¼‰ ----------
def request_whitelist_join(node_addr: str):
    """èŠ‚ç‚¹ç”³è¯·åŠ å…¥ç™½åå•"""
    if node_addr in AUTHENTICATED_NODES:
        log_print(f"[ç™½åå•] èŠ‚ç‚¹{node_addr[:8]}... å·²åœ¨ç™½åå•ä¸­")
        return True
    with IP_BIND_LOCK:
        if node_addr not in NODE_WHITELIST_REQUESTS:
            NODE_WHITELIST_REQUESTS[node_addr] = {}
        NODE_WHITELIST_REQUESTS[node_addr][NODE_ADDR] = time.time()
    # å‘æ‰€æœ‰å·²è®¤è¯èŠ‚ç‚¹å¹¿æ’­åŠ å…¥è¯·æ±‚
    for peer_addr in AUTHENTICATED_NODES:
        if peer_addr == NODE_ADDR:
            continue
        try:
            requests.post(
                f"http://{peer_addr}/json/whitelist/request",
                json={"node_addr": node_addr, "requester": NODE_ADDR},
                timeout=5
            )
        except Exception as e:
            log_print(f"[ç™½åå•] å‘èŠ‚ç‚¹{peer_addr[:8]}... å‘é€è¯·æ±‚å¤±è´¥ï¼š{e}")
    log_print(f"[ç™½åå•] èŠ‚ç‚¹{node_addr[:8]}... å·²å‘èµ·åŠ å…¥è¯·æ±‚ï¼Œç­‰å¾…å…±è¯†")
    return False

def approve_whitelist_request(request_node: str, approver_node: str):
    """è®¤å¯èŠ‚ç‚¹åŠ å…¥ç™½åå•ï¼ˆä»…å·²è®¤è¯èŠ‚ç‚¹å¯æŠ•ç¥¨ï¼‰"""
    if approver_node not in AUTHENTICATED_NODES:
        log_print(f"[ç™½åå•] èŠ‚ç‚¹{approver_node[:8]}... æœªè®¤è¯ï¼Œæ— æƒè®¤å¯")
        return
    with IP_BIND_LOCK:
        if request_node not in NODE_WHITELIST_REQUESTS:
            NODE_WHITELIST_REQUESTS[request_node] = {}
        NODE_WHITELIST_REQUESTS[request_node][approver_node] = time.time()
    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°å…±è¯†æ¯”ä¾‹
    approve_count = len(NODE_WHITELIST_REQUESTS[request_node])
    total_authenticated = len(AUTHENTICATED_NODES)
    if total_authenticated == 0:
        # æ— å·²è®¤è¯èŠ‚ç‚¹æ—¶ï¼Œé¦–æ¬¡åŠ å…¥ç›´æ¥é€šè¿‡
        AUTHENTICATED_NODES.add(request_node)
        log_print(f"[ç™½åå•] æ— å·²è®¤è¯èŠ‚ç‚¹ï¼ŒèŠ‚ç‚¹{request_node[:8]}... ç›´æ¥åŠ å…¥")
        return
    if approve_count / total_authenticated >= WHITELIST_CONSENSUS_RATIO:
        # è¾¾åˆ°å…±è¯†æ¯”ä¾‹ï¼ŒåŠ å…¥ç™½åå•
        AUTHENTICATED_NODES.add(request_node)
        if request_node in NODE_WHITELIST_REQUESTS:
            del NODE_WHITELIST_REQUESTS[request_node]
        broadcast_whitelist_update()
        log_print(f"[ç™½åå•] èŠ‚ç‚¹{request_node[:8]}... è·å¾—{approve_count}/{total_authenticated}è®¤å¯ï¼ŒåŠ å…¥ç™½åå•")

def broadcast_whitelist_update():
    """å¹¿æ’­ç™½åå•æ›´æ–°ç»™æ‰€æœ‰P2PèŠ‚ç‚¹"""
    for peer_addr in P2P_PEERS:
        try:
            requests.post(
                f"http://{peer_addr}/json/whitelist/update",
                json={"authenticated_nodes": list(AUTHENTICATED_NODES)},
                timeout=5
            )
        except Exception as e:
            log_print(f"[ç™½åå•] å‘èŠ‚ç‚¹{peer_addr[:8]}... å¹¿æ’­æ›´æ–°å¤±è´¥ï¼š{e}")

def sync_whitelist(remote_authenticated_nodes: list):
    """åŒæ­¥å…¶ä»–èŠ‚ç‚¹çš„ç™½åå•"""
    with IP_BIND_LOCK:
        local_count = len(AUTHENTICATED_NODES)
        remote_count = len(remote_authenticated_nodes)
        if remote_count > local_count and all(is_valid_address(node) for node in remote_authenticated_nodes):
            AUTHENTICATED_NODES.clear()
            AUTHENTICATED_NODES.update(remote_authenticated_nodes)
            log_print(f"[ç™½åå•] åŒæ­¥è¿œç¨‹ç™½åå•ï¼Œå½“å‰åˆæ³•èŠ‚ç‚¹æ•°ï¼š{len(AUTHENTICATED_NODES)}")

def clean_expired_whitelist():
    """æ¸…ç†è¿‡æœŸç™½åå•èŠ‚ç‚¹ï¼ˆæ¯å°æ—¶æ‰§è¡Œï¼‰"""
    while True:
        time.sleep(3600)
        with IP_BIND_LOCK:
            current_time = time.time()
            expired_nodes = []
            for node_addr in AUTHENTICATED_NODES:
                if node_addr not in P2P_PEERS or (current_time - P2P_PEERS[node_addr]) > WHITELIST_VALIDITY_PERIOD:
                    expired_nodes.append(node_addr)
            for node_addr in expired_nodes:
                AUTHENTICATED_NODES.remove(node_addr)
                log_print(f"[ç™½åå•] èŠ‚ç‚¹{node_addr[:8]}... è¿‡æœŸ/ç¦»çº¿ï¼Œç§»å‡ºç™½åå•")
            if expired_nodes:
                broadcast_whitelist_update()

# ---------- P2PåŒæ­¥ç›¸å…³å‡½æ•° ----------
def save_p2p_peer(peer_main_addr: str):
    """ä¿å­˜P2PèŠ‚ç‚¹"""
    with IP_BIND_LOCK:
        if peer_main_addr not in P2P_PEERS:
            P2P_PEERS[peer_main_addr] = time.time()
            conn = sqlite3.connect(DB_FILE)
            cur = conn.cursor()
            cur.execute("CREATE TABLE IF NOT EXISTS p2p_peers(peer_addr TEXT PRIMARY KEY, add_time REAL)")
            cur.execute("INSERT OR REPLACE INTO p2p_peers(peer_addr, add_time) VALUES (?, ?)", (peer_main_addr, time.time()))
            conn.commit()
            conn.close()

def p2p_discover_loop():
    """P2På‘ç°çº¿ç¨‹ï¼ˆå«èŠ‚ç‚¹å¿ƒè·³æ£€æµ‹ï¼‰"""
    while True:
        time.sleep(5)
        initial_seeds = P2P_SEEDS.copy()
        all_candidates = initial_seeds + list(P2P_PEERS.keys())
        random.shuffle(all_candidates)
        invalid_ips = {"127.0.0.1", "localhost", NODE_IP}
        local_main_addr = f"{CURRENT_NODE_PUBLIC_IP}:{PORT}"
        for candidate in all_candidates[:3]:
            if ":" not in candidate:
                continue
            peer_ip = candidate.rsplit(":", 1)[0]
            if peer_ip in invalid_ips:
                continue
            try:
                resp = requests.get(f"http://{candidate}/p2p/peers", timeout=10)
                if resp.status_code == 200:
                    data = resp.json()
                    if data["local_main_addr"] not in P2P_PEERS and data["local_main_addr"] != local_main_addr:
                        peer_main_ip = data["local_main_addr"].rsplit(":", 1)[0]
                        if peer_main_ip not in invalid_ips:
                            save_p2p_peer(data["local_main_addr"])
                    for peer_main_addr in data["peers"]:
                        if peer_main_addr not in P2P_PEERS and peer_main_addr != local_main_addr:
                            peer_main_ip = peer_main_addr.rsplit(":", 1)[0]
                            if peer_main_ip not in invalid_ips:
                                save_p2p_peer(peer_main_addr)
            except Exception as e:
                continue
        # æ¸…ç†æ— æ•ˆèŠ‚ç‚¹
        now = time.time()
        invalid_peers = []
        for addr in P2P_PEERS:
            if now - P2P_PEERS[addr] > 3600 or not is_peer_alive(addr):
                invalid_peers.append(addr)
        for addr in invalid_peers:
            del P2P_PEERS[addr]
            conn = sqlite3.connect(DB_FILE)
            cur = conn.cursor()
            cur.execute("DELETE FROM p2p_peers WHERE peer_addr=?", (addr,))
            conn.commit()
            conn.close()
            log_print(f"[P2Pæ¸…ç†] ç§»é™¤æ— æ•ˆèŠ‚ç‚¹ï¼š{addr}")

def sync_missing_blocks_from_peers():
    """åŒºå—åŒæ­¥ï¼ˆå«ç™½åå•+ç®—åŠ›æ ¡éªŒï¼‰"""
    global IS_SYNCING, IS_FULLY_SYNCED
    if IS_SYNCING:
        return
    IS_SYNCING = True
    try:
        local_max_height = get_chain_height()
        p2p_max_height = 0
        valid_p2p_nodes = []
        invalid_ips = {"127.0.0.1", "localhost", NODE_IP}
        valid_peers = [peer for peer in P2P_PEERS if not any(ip in peer for ip in invalid_ips)]
        # è·å–æœ‰æ•ˆèŠ‚ç‚¹å’Œç›®æ ‡é“¾é«˜
        for peer_main_addr in valid_peers:
            try:
                resp = requests.get(f"http://{peer_main_addr}/json/chain_height", timeout=10)
                if resp.status_code == 200:
                    peer_height = resp.json()["height"]
                    if peer_height > p2p_max_height:
                        p2p_max_height = peer_height
                    valid_p2p_nodes.append(peer_main_addr)
            except:
                continue
        if not valid_p2p_nodes:
            IS_FULLY_SYNCED = True
            log_print(f"â™»ï¸[åŒæ­¥å®Œæˆ] æ— æœ‰æ•ˆP2PèŠ‚ç‚¹ï¼Œå•èŠ‚ç‚¹æ¨¡å¼")
            return
        if p2p_max_height > local_max_height:
            log_print(f"â™»ï¸[åŒæ­¥] P2Pæœ€é«˜{p2p_max_height} > æœ¬åœ°{local_max_height}ï¼Œå¼€å§‹åŒæ­¥")
            batch_size = 10
            for batch_start in range(local_max_height + 1, p2p_max_height + 1, batch_size):
                batch_end = min(batch_start + batch_size - 1, p2p_max_height)
                log_print(f"â™»ï¸[æ‰¹æ¬¡åŒæ­¥] åŒæ­¥åŒºå— {batch_start}-{batch_end}")
                for height in range(batch_start, batch_end + 1):
                    block = None
                    block_hash_map = {}
                    retry_count = 0
                    # æ”¶é›†å¤šèŠ‚ç‚¹åŒºå—ï¼ŒéªŒè¯åˆæ³•æ€§
                    while retry_count < 3 and len(block_hash_map) < 2:
                        for peer_main_addr in valid_p2p_nodes:
                            try:
                                time.sleep(0.5)
                                resp = requests.get(f"http://{peer_main_addr}/json/block/{height}", timeout=20)
                                if resp.status_code == 429:
                                    log_print(f"â™»ï¸[é™æµè§¦å‘] èŠ‚ç‚¹{peer_main_addr}è¯·æ±‚é¢‘ç¹ï¼Œæš‚åœ30ç§’")
                                    time.sleep(30)
                                    continue
                                if resp.status_code == 200:
                                    peer_block = resp.json()["block"]
                                    # æ ¡éªŒåŒºå—åŸºæœ¬åˆæ³•æ€§
                                    if not is_valid_address(peer_block["miner"]):
                                        continue
                                    # è®¡ç®—åŒºå—å“ˆå¸Œ
                                    calc_dict = {k: v for k, v in peer_block.items() if k != "prev_hash"}
                                    block_hash = hashlib.sha256(json.dumps(calc_dict, sort_keys=True).encode()).hexdigest()
                                    # ç»Ÿè®¡å“ˆå¸Œå…±è¯†
                                    if block_hash in block_hash_map:
                                        block_hash_map[block_hash] += 1
                                    else:
                                        block_hash_map[block_hash] = 1
                            except:
                                continue
                        retry_count += 1
                    # è·å–å…±è¯†åŒºå—
                    if block_hash_map:
                        consensus_hash = max(block_hash_map.items(), key=lambda x: x[1])[0]
                        for peer_main_addr in valid_p2p_nodes:
                            try:
                                time.sleep(0.5)
                                resp = requests.get(f"http://{peer_main_addr}/json/block/{height}", timeout=20)
                                if resp.status_code == 200:
                                    peer_block = resp.json()["block"]
                                    calc_dict = {k: v for k, v in peer_block.items() if k != "prev_hash"}
                                    if hashlib.sha256(json.dumps(calc_dict, sort_keys=True).encode()).hexdigest() == consensus_hash:
                                        block = Block(**peer_block)
                                        break
                            except:
                                continue
                    # ä¿å­˜åŒºå—
                    if block:
                        save_block_to_full_chain(block)
                        log_print(f"â™»ï¸ [åŒæ­¥æˆåŠŸ] é«˜åº¦{height}ï¼ˆå…±è¯†å“ˆå¸Œï¼š{consensus_hash[:8]}...ï¼‰")
                    else:
                        log_print(f"â™»ï¸[åŒæ­¥å¤±è´¥] é«˜åº¦{height}ï¼ˆæœªè¾¾æˆå…±è¯†ï¼‰")
                time.sleep(10)
            local_max_height = get_chain_height()
        IS_FULLY_SYNCED = local_max_height >= p2p_max_height
        status = "å®Œæˆ" if IS_FULLY_SYNCED else "ä¸­"
        log_print(f"â™»ï¸[åŒæ­¥{status}] æœ¬åœ°{local_max_height} | é›†ç¾¤{p2p_max_height}")
    finally:
        IS_SYNCING = False

def sync_loop():
    """åŒæ­¥å¾ªç¯çº¿ç¨‹"""
    while True:
        sync_missing_blocks_from_peers()
        time.sleep(SYNC_INTERVAL)

# ---------- æŒ–çŸ¿ç›¸å…³å‡½æ•° ----------
def get_balance_from_cache(addr: str, max_height: int) -> int:
    """æŒ‰åœ°å€+æœ€å¤§é«˜åº¦ç¼“å­˜ä½™é¢"""
    if not is_valid_address(addr):
        log_print(f"[ä½™é¢è®¡ç®—å¤±è´¥] åœ°å€æ ¼å¼æ— æ•ˆï¼š{addr}")
        return 0
    cache_key = f"{addr}_{max_height}"
    if cache_key in BALANCE_CACHE:
        return BALANCE_CACHE[cache_key]
    balance = 0
    try:
        # éå†å…¨é‡åŒºå—è®¡ç®—ä½™é¢
        for height in range(1, max_height + 1):
            block = get_block_from_full_chain(height)
            if not block:
                continue
            # ç´¯åŠ çŸ¿å·¥å¥–åŠ±
            if block.miner == addr:
                balance += block.reward
            # å¤„ç†äº¤æ˜“
            for tx in block.txs:
                if tx.get("sender") == addr:
                    balance = max(0, balance - (tx["amount"] + FEE))
                if tx.get("recipient") == addr:
                    balance += tx["amount"]
    except Exception as e:
        log_print(f"[é”™è¯¯] è®¡ç®—åœ°å€{addr[:8]}...ä½™é¢å¤±è´¥ï¼š{e}")
        balance = 0
    # ç¼“å­˜ç»“æœ
    BALANCE_CACHE[cache_key] = max(balance, 0)
    return BALANCE_CACHE[cache_key]

def miner_loop():
    """æŒ–çŸ¿å¾ªç¯çº¿ç¨‹ï¼ˆä»…ç™½åå•èŠ‚ç‚¹å¯æŒ–çŸ¿ï¼‰"""
    global IS_FULLY_SYNCED, TX_POOL
    # å¯åŠ¨æ—¶è‡ªåŠ¨ç”³è¯·åŠ å…¥ç™½åå•
    if NODE_ADDR not in AUTHENTICATED_NODES:
        request_whitelist_join(NODE_ADDR)
    while True:
        # æœªåŒæ­¥å®Œæˆ/æœªåŠ å…¥ç™½åå•ï¼Œä¸æŒ–çŸ¿
        if not IS_FULLY_SYNCED:
            log_print(f"[ç­‰å¾…] åŒæ­¥ä¸­ï¼ˆæœ¬åœ°é«˜åº¦{get_chain_height()}ï¼‰ï¼Œæš‚ä¸æŒ–çŸ¿")
            time.sleep(10)
            continue
        if NODE_ADDR not in AUTHENTICATED_NODES:
            log_print(f"[ç­‰å¾…] æœªåŠ å…¥ç™½åå•ï¼Œæš‚ä¸æŒ–çŸ¿ï¼ˆå½“å‰ç™½åå•èŠ‚ç‚¹æ•°ï¼š{len(AUTHENTICATED_NODES)}ï¼‰")
            time.sleep(30)
            request_whitelist_join(NODE_ADDR)
            continue
        time.sleep(60)  # æ¯åˆ†é’Ÿå°è¯•å‡ºå—ä¸€æ¬¡
        with QUEUE_LOCK:
            if not GLOBAL_QUEUE:
                GLOBAL_QUEUE.extend(AUTHENTICATED_NODES)  # ç™½åå•èŠ‚ç‚¹æ’é˜ŸæŒ–çŸ¿
            current_miner = GLOBAL_QUEUE[0]
        # å½“å‰ä¸æ˜¯æœ¬èŠ‚ç‚¹æŒ–çŸ¿ï¼Œç­‰å¾…
        if current_miner != NODE_ADDR:
            log_print(f"[ç­‰å¾…] å½“å‰æŒ–çŸ¿èŠ‚ç‚¹ï¼š{current_miner[:8]}...ï¼Œæœ¬èŠ‚ç‚¹æ’é˜Ÿä¸­")
            continue
        # è®¡ç®—æ€»å‘è¡Œé‡ä¸åˆæ³•å¥–åŠ±
        current_supply = get_total_supply()
        block_reward = REWARD if (current_supply + REWARD) <= TOTAL_SUPPLY_LIMIT else 0
        prev_height = get_chain_height()
        prev_block = get_block_from_full_chain(prev_height) if prev_height > 0 else None
        prev_hash = hashlib.sha256(json.dumps(asdict(prev_block)).encode()).hexdigest() if prev_block else "0"*64
        # ç­›é€‰æœ‰æ•ˆäº¤æ˜“
        with TX_POOL_LOCK:
            sorted_txs = sorted(TX_POOL, key=lambda x: (x["sender"], x["nonce"]))
        valid_txs = []
        for tx in sorted_txs:
            if not verify_tx_signature(tx):
                continue
            sender_bal = get_balance_from_cache(tx["sender"], prev_height)
            if sender_bal >= (tx["amount"] + FEE):
                valid_txs.append(tx)
        # æ„å»ºå¹¶ä¿å­˜åŒºå—
        blk = Block(
            height=prev_height + 1,
            prev_hash=prev_hash,
            miner=current_miner,
            txs=valid_txs,
            reward=block_reward
        )
        save_block_to_full_chain(blk)
        # å¹¿æ’­åŒºå—åˆ°æ‰€æœ‰P2PèŠ‚ç‚¹
        for peer_addr in P2P_PEERS:
            try:
                requests.post(f"http://{peer_addr}/json/submit_block", json=asdict(blk), timeout=8)
            except:
                continue
        # æ›´æ–°æŒ–çŸ¿é˜Ÿåˆ—å’Œäº¤æ˜“æ± 
        with QUEUE_LOCK:
            GLOBAL_QUEUE.pop(0)
            GLOBAL_QUEUE.append(current_miner)
        with TX_POOL_LOCK:
            packed_hashes = {hashlib.sha256(json.dumps(tx, sort_keys=True).encode()).hexdigest() for tx in valid_txs}
            TX_POOL = [tx for tx in TX_POOL if hashlib.sha256(json.dumps(tx, sort_keys=True).encode()).hexdigest() not in packed_hashes]
        # æ‰“å°æ—¥å¿—
        log_print(f"[åˆæ³•å‡ºå—] é«˜åº¦#{blk.height} | çŸ¿å·¥{blk.miner[:8]}... | å¥–åŠ±{blk.reward} | äº¤æ˜“æ•°{len(valid_txs)}")

# ---------- HTTPè¯·æ±‚å¤„ç†å™¨ ----------
class MainHandler(http.server.BaseHTTPRequestHandler):
    def send_json(self, data: Dict):
        """å‘é€JSONå“åº”"""
        self.send_response(200)
        self.send_header("Content-Type", "application/json; charset=utf-8")
        self.end_headers()
        try:
            self.wfile.write(json.dumps(data).encode())
        except BrokenPipeError:
            pass

    def handle(self):
        """è¯·æ±‚é™æµ+å…¨å±€å¹¶å‘æ§åˆ¶"""
        # å…¨å±€å¹¶å‘é™åˆ¶
        if not GLOBAL_REQUEST_SEMAPHORE.acquire(blocking=False):
            self.send_response(503)
            self.send_header("Content-Type", "application/json; charset=utf-8")
            self.end_headers()
            self.wfile.write(json.dumps({"status": "fail", "msg": "èŠ‚ç‚¹ç¹å¿™ï¼Œè¯·ç¨åé‡è¯•"}).encode())
            return
        try:
            # å•IPé™æµé€»è¾‘
            client_ip = self.client_address[0]
            now = time.time()
            with IP_BIND_LOCK:
                if client_ip not in IP_REQUEST_COUNT:
                    IP_REQUEST_COUNT[client_ip] = (1, now)
                else:
                    count, last_reset = IP_REQUEST_COUNT[client_ip]
                    if now - last_reset > 60:
                        IP_REQUEST_COUNT[client_ip] = (1, now)
                    else:
                        if count >= REQUEST_LIMIT_PER_MINUTE:
                            self.send_response(429)
                            self.send_header("Content-Type", "application/json; charset=utf-8")
                            self.end_headers()
                            self.wfile.write(json.dumps({"status": "fail", "msg": "è¯·æ±‚è¿‡äºé¢‘ç¹"}).encode())
                            return
                        IP_REQUEST_COUNT[client_ip] = (count + 1, last_reset)
            super().handle()
        finally:
            GLOBAL_REQUEST_SEMAPHORE.release()

    def do_GET(self):
        """å¤„ç†GETè¯·æ±‚"""
        # 1. é“¾é«˜æŸ¥è¯¢
        if self.path == "/json/chain_height":
            height = get_chain_height()
            self.send_json({"height": height})
        # 2. æŒ–çŸ¿é˜Ÿåˆ—æŸ¥è¯¢
        elif self.path == "/json/global_queue":
            with QUEUE_LOCK:
                self.send_json({"queue": GLOBAL_QUEUE})
        # 3. å•ä¸ªåŒºå—æŸ¥è¯¢
        elif self.path.startswith("/json/block/"):
            try:
                height = int(self.path.split("/")[-1])
                block = get_block_from_full_chain(height)
                if block:
                    self.send_json({"block": asdict(block), "status": "success"})
                else:
                    self.send_json({"status": "fail", "msg": "åŒºå—ä¸å­˜åœ¨"})
            except:
                self.send_json({"status": "fail", "msg": "å‚æ•°é”™è¯¯"})
        # 4. P2PèŠ‚ç‚¹åˆ—è¡¨æŸ¥è¯¢
        elif self.path == "/p2p/peers":
            with IP_BIND_LOCK:
                self.send_json({"local_main_addr": f"{CURRENT_NODE_PUBLIC_IP}:{PORT}", "peers": list(P2P_PEERS.keys())})
        # 5. èŠ‚ç‚¹çŠ¶æ€æŸ¥è¯¢
        elif self.path == "/json/node_status":
            with IP_BIND_LOCK:
                peer_count = len(P2P_PEERS)
            status = {
                "node_addr": NODE_ADDR,
                "current_height": get_chain_height(),
                "p2p_peer_count": peer_count,
                "mining_status": "running" if IS_FULLY_SYNCED and NODE_ADDR in AUTHENTICATED_NODES else "waiting",
                "tx_pool_size": len(TX_POOL),
                "storage_mode": "full_chain",
                "address_format": f"{ADDRESS_PREFIX} + 32ä½å“ˆå¸Œï¼ˆå…±36ä½ï¼‰",
                "whitelist_count": len(AUTHENTICATED_NODES),
                "is_authenticated": NODE_ADDR in AUTHENTICATED_NODES
            }
            self.send_json(status)
        # 6. ä½™é¢æŸ¥è¯¢ï¼ˆåŸºäºå…¨ç½‘å…±è¯†ï¼‰
        elif self.path.startswith("/json/query_balance?"):
            try:
                params = dict([p.split("=") for p in self.path.split("?")[1].split("&")])
                addr = params.get("addr", "")
                if not is_valid_address(addr):
                    self.send_json({"status": "fail", "msg": "åœ°å€æ ¼å¼æ— æ•ˆï¼ˆéœ€36ä½RNDCå‰ç¼€åœ°å€ï¼‰"})
                    return
                max_height = get_chain_height()
                balance = get_balance_from_cache(addr, max_height)
                self.send_json({
                    "status": "success",
                    "addr": addr,
                    "balance": balance,
                    "chain_height": max_height,
                    "query_mode": "consensus"
                })
            except Exception as e:
                self.send_json({"status": "fail", "msg": f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}"})
        # 7. ç™½åå•æŸ¥è¯¢
        elif self.path == "/json/whitelist":
            self.send_json({
                "authenticated_nodes": list(AUTHENTICATED_NODES),
                "request_count": len(NODE_WHITELIST_REQUESTS)
            })
        # 404
        else:
            self.send_response(404)
            self.end_headers()

    def do_POST(self):
        """å¤„ç†POSTè¯·æ±‚"""
        content_length = int(self.headers.get("Content-Length", 0))
        data = json.loads(self.rfile.read(content_length).decode())
        # 1. åŒºå—æäº¤
        if self.path == "/json/submit_block":
            try:
                block = Block(**data)
                current_max_height = get_chain_height()
                if block.height == current_max_height + 1 and is_valid_address(block.miner):
                    save_block_to_full_chain(block)
                    log_print(f"[æ¥æ”¶] é«˜åº¦{block.height}ï¼ˆçŸ¿å·¥ï¼š{block.miner[:8]}...ï¼‰")
                    self.send_json({"status": "success"})
                else:
                    self.send_json({"status": "fail", "msg": "åŒºå—é«˜åº¦æ— æ•ˆæˆ–çŸ¿å·¥åœ°å€æ ¼å¼é”™è¯¯"})
            except:
                self.send_json({"status": "fail", "msg": "åŒºå—æ ¼å¼é”™è¯¯"})
        # 2. äº¤æ˜“æäº¤
        elif self.path == "/json/submit_tx":
            if not verify_tx_signature(data):
                self.send_json({"status": "fail", "msg": "äº¤æ˜“ç­¾åæ— æ•ˆæˆ–åœ°å€æ ¼å¼é”™è¯¯"})
                return
            with TX_POOL_LOCK:
                if len(TX_POOL) >= MAX_TX_POOL_SIZE:
                    TX_POOL.pop(0)
                    log_print(f"[äº¤æ˜“æ± æ¸…ç†] å®¹é‡å·²æ»¡ï¼Œç§»é™¤æœ€æ—§äº¤æ˜“")
                TX_POOL.append(data)
            self.send_json({"status": "success", "msg": "äº¤æ˜“å·²åŠ å…¥æ± "})
        # 3. ç™½åå•åŠ å…¥è¯·æ±‚ï¼ˆæ ¸å¿ƒæ–°å¢ï¼‰
        elif self.path == "/json/whitelist/request":
            request_node = data.get("node_addr", "")
            requester = data.get("requester", "")
            if not is_valid_address(request_node) or not is_valid_address(requester):
                self.send_json({"status": "fail", "msg": "åœ°å€æ ¼å¼æ— æ•ˆ"})
                return
            if NODE_ADDR in AUTHENTICATED_NODES:
                approve_whitelist_request(request_node, NODE_ADDR)
                self.send_json({"status": "success", "msg": "å·²è®¤å¯è¯·æ±‚"})
            else:
                self.send_json({"status": "fail", "msg": "æœ¬èŠ‚ç‚¹æœªè®¤è¯ï¼Œæ— æƒè®¤å¯"})
        # 4. ç™½åå•æ›´æ–°åŒæ­¥ï¼ˆæ ¸å¿ƒæ–°å¢ï¼‰
        elif self.path == "/json/whitelist/update":
            remote_nodes = data.get("authenticated_nodes", [])
            if isinstance(remote_nodes, list) and all(is_valid_address(node) for node in remote_nodes):
                sync_whitelist(remote_nodes)
                self.send_json({"status": "success", "msg": "ç™½åå•å·²åŒæ­¥"})
            else:
                self.send_json({"status": "fail", "msg": "ç™½åå•æ ¼å¼æ— æ•ˆ"})
        # 404
        else:
            self.send_response(404)
            self.end_headers()

# ---------- å¯åŠ¨P2PæœåŠ¡ ----------
def start_p2p_server():
    """å¯åŠ¨P2PæœåŠ¡"""
    p2p_handler = MainHandler
    p2p_httpd = socketserver.TCPServer(("0.0.0.0", P2P_DISCOVERY_PORT), p2p_handler)
    log_print(f"[P2P] æœåŠ¡å¯åŠ¨ï¼š{P2P_DISCOVERY_PORT}ç«¯å£")
    p2p_httpd.serve_forever()

# ---------- é€€å‡ºå¤„ç† ----------
def exit_handler():
    """ç¨‹åºé€€å‡ºæ—¶æ¸…ç†èµ„æº"""
    with IP_BIND_LOCK:
        if NODE_ADDR in ADDR_IP_MAP:
            ip = ADDR_IP_MAP[NODE_ADDR]
            conn = sqlite3.connect(DB_FILE)
            cur = conn.cursor()
            cur.execute("DELETE FROM ip_addr_map WHERE addr=?", (NODE_ADDR,))
            conn.commit()
            conn.close()

# ---------- ä¸»å‡½æ•° ----------
if __name__ == "__main__":
    log_print("[Node] å¼€å§‹åˆå§‹åŒ–...ï¼ˆæ— ç®—åŠ›+åŠ¨æ€ç™½åå•+é˜²ç¯¡æ”¹ï¼‰")
    # åˆå§‹åŒ–æ•°æ®åº“
    init_full_chain_db()
    # æ ¡éªŒæœ¬åœ°æ•°æ®å®Œæ•´æ€§
    verify_local_chain_integrity()
    # åŠ è½½é…ç½®ä¸é’±åŒ…
    NODE_IP = get_local_ip()
    NODE_KEY, NODE_ADDR, ENCRYPTOR = init_wallet()
    load_ip_addr_map()
    load_p2p_peers()
    bind_ip_address(NODE_IP, NODE_ADDR)
    atexit.register(exit_handler)
    # å¯åŠ¨ç™½åå•æ¸…ç†çº¿ç¨‹
    whitelist_clean_thread = threading.Thread(target=clean_expired_whitelist, daemon=True)
    whitelist_clean_thread.start()
    # å¯åŠ¨æ ¸å¿ƒæœåŠ¡çº¿ç¨‹
    log_print("\n[å¯åŠ¨çº¿ç¨‹] å¼€å§‹å¯åŠ¨æ ¸å¿ƒæœåŠ¡...")
    p2p_server_thread = threading.Thread(target=start_p2p_server, daemon=True)
    p2p_server_thread.start()
    p2p_discover_thread = threading.Thread(target=p2p_discover_loop, daemon=True)
    p2p_discover_thread.start()
    sync_thread = threading.Thread(target=sync_loop, daemon=True)
    sync_thread.start()
    miner_thread = threading.Thread(target=miner_loop, daemon=True)
    miner_thread.start()
    # å¯åŠ¨ä¸»æœåŠ¡
    main_handler = MainHandler
    main_httpd = socketserver.TCPServer(("0.0.0.0", PORT), main_handler)
    log_print(f"\n[*] èŠ‚ç‚¹å¯åŠ¨æˆåŠŸï¼ï¼ˆæ— ç®—åŠ›+åŠ¨æ€ç™½åå•ï¼‰")
    log_print(f"[*] ä¸»æœåŠ¡ï¼š{PORT}ç«¯å£ | P2PæœåŠ¡ï¼š{P2P_DISCOVERY_PORT}ç«¯å£")
    log_print(f"[*] èŠ‚ç‚¹åœ°å€ï¼š{NODE_ADDR} | è´¦æœ¬æ–‡ä»¶ï¼š{DB_FILE}")
    log_print(f"[*] ç™½åå•èŠ‚ç‚¹æ•°ï¼š{len(AUTHENTICATED_NODES)} | ç­‰å¾…åŠ å…¥è¯·æ±‚æ•°ï¼š{len(NODE_WHITELIST_REQUESTS)}")
    main_httpd.serve_forever()
